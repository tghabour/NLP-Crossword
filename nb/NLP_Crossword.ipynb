{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Crossword Puzzles\n",
    "**Tony Ghabour**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#NLP---Crossword-Puzzles\" data-toc-modified-id=\"NLP---Crossword-Puzzles-1\">NLP - Crossword Puzzles</a></span></li><li><span><a href=\"#Initial-Setup\" data-toc-modified-id=\"Initial-Setup-2\">Initial Setup</a></span></li><li><span><a href=\"#Data-Work\" data-toc-modified-id=\"Data-Work-3\">Data Work</a></span><ul class=\"toc-item\"><li><span><a href=\"#Retreival\" data-toc-modified-id=\"Retreival-3.1\">Retreival</a></span></li><li><span><a href=\"#Store-in-MongoDB\" data-toc-modified-id=\"Store-in-MongoDB-3.2\">Store in MongoDB</a></span></li><li><span><a href=\"#Retreive-from-MongoDB\" data-toc-modified-id=\"Retreive-from-MongoDB-3.3\">Retreive from MongoDB</a></span></li><li><span><a href=\"#Processing\" data-toc-modified-id=\"Processing-3.4\">Processing</a></span></li></ul></li><li><span><a href=\"#Puzzle-Class/Objects\" data-toc-modified-id=\"Puzzle-Class/Objects-4\">Puzzle Class/Objects</a></span><ul class=\"toc-item\"><li><span><a href=\"#Grids-(Heatmaps)\" data-toc-modified-id=\"Grids-(Heatmaps)-4.1\">Grids (Heatmaps)</a></span></li></ul></li><li><span><a href=\"#EDA\" data-toc-modified-id=\"EDA-5\">EDA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Answers\" data-toc-modified-id=\"Answers-5.1\">Answers</a></span></li><li><span><a href=\"#Clues\" data-toc-modified-id=\"Clues-5.2\">Clues</a></span></li></ul></li><li><span><a href=\"#NLP-Analysis\" data-toc-modified-id=\"NLP-Analysis-6\">NLP Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dimensionality-Reduction\" data-toc-modified-id=\"Dimensionality-Reduction-6.1\">Dimensionality Reduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Vectorize-Corpus\" data-toc-modified-id=\"Vectorize-Corpus-6.1.1\">Vectorize Corpus</a></span></li><li><span><a href=\"#LSA\" data-toc-modified-id=\"LSA-6.1.2\">LSA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Count\" data-toc-modified-id=\"Count-6.1.2.1\">Count</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-6.1.2.2\">TF-IDF</a></span></li></ul></li><li><span><a href=\"#NMF\" data-toc-modified-id=\"NMF-6.1.3\">NMF</a></span><ul class=\"toc-item\"><li><span><a href=\"#Count\" data-toc-modified-id=\"Count-6.1.3.1\">Count</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-6.1.3.2\">TF-IDF</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-7\">Classification</a></span></li><li><span><a href=\"#Future-Work\" data-toc-modified-id=\"Future-Work-8\">Future Work</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Standard Libraries \n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import xword\n",
    "import json\n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import statistics as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from string import digits\n",
    "from datetime import datetime \n",
    "from collections import Counter \n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database management \n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP & Text Processing\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Model Tools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to load puzzle: ../data/raw/2017/12/03.json\n",
      "Unable to load puzzle: ../data/raw/2018/03/08.json\n"
     ]
    }
   ],
   "source": [
    "all_puzzles = []\n",
    "base_path = '../data/raw/'\n",
    "puzzle_paths = xword.get_jsons(base_path)\n",
    "\n",
    "for json_file_path in puzzle_paths:\n",
    "    with open(json_file_path) as json_file:\n",
    "        try:\n",
    "            all_puzzles.append(json.load(json_file))\n",
    "        except:\n",
    "            print(f'Unable to load puzzle: {json_file_path}')\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store in MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.NYT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['puzzle_collection']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#db.create_collection(\"puzzle_collection\") # only run once \n",
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = db.get_collection(\"puzzle_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pc.insert_many(all_puzzles) # only run once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14545, 14545)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_puzzles), pc.count_documents({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreive from MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = {'_id': 0, \n",
    "              'acrossmap': 0, \n",
    "              'admin': 0, \n",
    "              'autowrap': 0,\n",
    "              'bbars': 0,\n",
    "              'code': 0, \n",
    "              'copyright': 0,\n",
    "              'rbars': 0, \n",
    "              'track': 0, \n",
    "              'downmap': 0, \n",
    "              'mini': 0, \n",
    "              'key': 0, \n",
    "              'id': 0, \n",
    "              'id2': 0,\n",
    "              'interpretcolors': 0,   \n",
    "              'hold': 0,\n",
    "              'publisher': 0, \n",
    "              'uniclue' : 0,\n",
    "              'valid': 0,\n",
    "              'type': 0}\n",
    "\n",
    "filter_ = {'uniclue': {\"$ne\": True}}\n",
    "\n",
    "cursor = pc.find(filter_,projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df = pd.DataFrame(list(cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14544 entries, 0 to 14543\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   answers       14544 non-null  object\n",
      " 1   author        14544 non-null  object\n",
      " 2   circles       346 non-null    object\n",
      " 3   clues         14544 non-null  object\n",
      " 4   date          14544 non-null  object\n",
      " 5   dow           14544 non-null  object\n",
      " 6   editor        14544 non-null  object\n",
      " 7   grid          14544 non-null  object\n",
      " 8   gridnums      14544 non-null  object\n",
      " 9   jnotes        503 non-null    object\n",
      " 10  notepad       202 non-null    object\n",
      " 11  shadecircles  59 non-null     object\n",
      " 12  size          14544 non-null  object\n",
      " 13  title         14544 non-null  object\n",
      " 14  hastitle      473 non-null    object\n",
      "dtypes: object(15)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "pc_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create fields in dataframe for number of rows and columns in each crossword puzzle\n",
    "pc_df['rows'] = pc_df['size'].apply(lambda x: x['rows'])\n",
    "pc_df['cols'] = pc_df['size'].apply(lambda x: x['cols'])\n",
    "\n",
    "# Aggregate down+accross clues and answers in separate fields\n",
    "pc_df['all_clues'] = pc_df['clues'].apply(lambda x: x['across'] + x['down']) \n",
    "pc_df['all_answers'] = pc_df['answers'].apply(lambda x: x['across'] + x['down']) \n",
    "\n",
    "# Clean up redundant data\n",
    "pc_df = pc_df.drop(['size', \n",
    "                    'clues', \n",
    "                    'answers'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df['clean_clues'] = pc_df['all_clues'].apply(lambda x: xword.process_text(x))\n",
    "pc_df['clean_answers'] = pc_df['all_answers'].apply(lambda x: xword.process_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df.to_csv('../data/processed/cleaned_corpus.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puzzle Class/Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify date range over which to retrieve/inspect puzzles.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.date(2000, 1, 1)\n",
    "end_date = dt.date(2004, 1, 1)\n",
    "dt_range = xword.date_range(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_puzzles = xword.get_puzzles(dt_range)\n",
    "puzzle_count = len(list_of_puzzles)\n",
    "random_index = random.choice(range(puzzle_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_puzzle = xword.puzzle()\n",
    "sample_puzzle.parse_puzzle(list_of_puzzles[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we can use our class to drill down and investigate attributes of an individual puzzle or group of puzzles.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_puzzle.date, sample_puzzle.dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_puzzle.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_puzzle.editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_puzzle.clues.across"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_puzzle.clues.down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_puzzle.answers.across"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_puzzle.answers.down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_puzzle.blank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_puzzle.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grids (Heatmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xword.heat_map(list_of_puzzles, days = ['Monday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xword.heat_map(list_of_puzzles, days = ['Tuesday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xword.heat_map(list_of_puzzles, days = ['Wednesday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xword.heat_map(list_of_puzzles, days = ['Thursday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xword.heat_map(list_of_puzzles, days = ['Friday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xword.heat_map(list_of_puzzles, days = ['Saturday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xword.heat_map(list_of_puzzles, days = ['Sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xword.heat_map(list_of_puzzles, days = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pull in clean data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df = pd.read_csv('../data/processed/cleaned_corpus.csv')\n",
    "pc_df = pc_df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df['all_clues'] = pc_df['all_clues'].apply(lambda x: ast.literal_eval(x))\n",
    "pc_df['all_answers'] = pc_df['all_answers'].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "#\n",
    "pc_df['clean_clues'] = pc_df['clean_clues'].apply(lambda x: xword.reduce_col(x))\n",
    "pc_df['clean_answers'] = pc_df['clean_answers'].apply(lambda x: xword.reduce_col(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Total number of puzzles in corpus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count number of unique authors.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df.author.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's take a look at the answers...specifically, statistics relating to answer lengths and novelty/uniqueness.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df['ans_lens'] = pc_df['all_answers'].apply(lambda x: [len(y) for y in x])\n",
    "pc_df['min_len'] = pc_df['ans_lens'].apply(lambda x: min(x))\n",
    "pc_df['max_len'] = pc_df['ans_lens'].apply(lambda x: max(x))\n",
    "pc_df['mean_len'] = pc_df['ans_lens'].apply(lambda x: st.mean(x))\n",
    "pc_df['median_len'] = pc_df['ans_lens'].apply(lambda x: st.median(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df = pc_df.set_index(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_only = (pd.melt(answer_df.all_answers.apply(pd.Series).reset_index(), \n",
    "                id_vars=['date'], \n",
    "                value_name='all_answers')\n",
    "               .set_index(['date'])\n",
    "               .drop('variable', axis=1)\n",
    "               .dropna()\n",
    "               .sort_index()\n",
    "              ).reset_index()\n",
    "\n",
    "answers_only = answers_only.sort_values(['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = set()\n",
    "new_ans_dates = []\n",
    "for idx, row in answers_only.iterrows():\n",
    "    if row[1] in answers:\n",
    "        pass\n",
    "    else:\n",
    "        new_ans_dates.append(row.date)\n",
    "        answers.add(row[1])\n",
    "        \n",
    "new_ans = Counter()\n",
    "for date in new_ans_dates: \n",
    "    new_ans[date] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_df = pd.DataFrame.from_dict(new_ans, orient='index').reset_index()\n",
    "answers_df = answers_df.rename({0:'unique_ans_count', 'index': 'date'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_df['date_dt'] = answers_df['date'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y').date())\n",
    "answers_df['dow_int'] = answers_df.date_dt.apply(lambda x: x.weekday()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = answers_df.groupby(['dow_int']).mean().reset_index()\n",
    "dow_labels = ('MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN')\n",
    "\n",
    "x = plot_data['dow_int']\n",
    "y = plot_data['unique_ans_count']\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(range(7), dow_labels)\n",
    "plt.yticks(np.arange(0, 25, step=2))\n",
    "\n",
    "plt.ylabel('Average Count', size = 14)\n",
    "\n",
    "bars = plt.bar(x, y, color='silver');\n",
    "bars[6].set_color('crimson')\n",
    "\n",
    "plt.title('First Appearance by Day of Week', size = 16);\n",
    "\n",
    "plt.savefig(\"../img/avg_unique_words.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df['fillin_pct'] = pc_df.all_clues.apply(lambda x: xword.fillin_pct(x))\n",
    "pc_df['quotes_pct'] = pc_df.all_clues.apply(lambda x: xword.quotes_pct(x))\n",
    "pc_df['ques_pct'] = pc_df.all_clues.apply(lambda x: xword.ques_pct(x))\n",
    "pc_df['self_ref'] = pc_df.all_clues.apply(lambda x: xword.self_ref(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df['date_dt'] = pc_df['date'].apply(lambda x: datetime.strptime(x, '%m/%d/%Y').date())\n",
    "pc_df['dow_int'] = pc_df.date_dt.apply(lambda x: x.weekday()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pc_df.groupby(['dow_int']).mean().reset_index() #.drop(['rows', 'cols'], axis = 1)\n",
    "plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow_labels = ('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(range(7), dow_labels)\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "plt.plot(plot_data['dow_int'], plot_data['fillin_pct'], alpha = 1, linestyle=':', color = 'grey')\n",
    "plt.plot(plot_data['dow_int'], plot_data['quotes_pct'], alpha = 1, linestyle='-.', color = 'grey')\n",
    "plt.plot(plot_data['dow_int'], plot_data['self_ref'], alpha = 1, linestyle='--', color = 'grey')\n",
    "plt.plot(plot_data['dow_int'], plot_data['ques_pct'], color = 'crimson');\n",
    "\n",
    "plt.title('Occurence of Common Clue Types', size = 16)\n",
    "plt.ylabel('Percentage of Clues', size = 14)\n",
    "plt.yticks(np.arange(0, .11, step=.01))\n",
    "plt.legend(['Fill in the Blank', 'Quotations', 'Self-Referential', 'Word Play'], loc='upper center', ncol=4);\n",
    "\n",
    "plt.savefig(\"../img/clue_types.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pc_df['clean_clues']\n",
    "docs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (2,3), stop_words = 'english', min_df = .0002) #, max_df = .0005\n",
    "#cv = CountVectorizer(ngram_range = (2,2), stop_words = 'english', min_df = .0002) #, max_df = .0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_cv = cv.fit_transform(docs)\n",
    "pd.DataFrame(doc_word_cv.toarray(), index=list(docs.index), columns=cv.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(ngram_range = (2,3), stop_words = 'english', min_df = .0002) #, max_df = .0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_tf = tf.fit_transform(docs)\n",
    "pd.DataFrame(doc_word_tf.toarray(), index=list(docs.index), columns=tf.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_lsa_cv = lsa.fit_transform(doc_word_cv)\n",
    "sum(lsa.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_lsa_cv = pd.DataFrame(lsa.components_.round(3),\n",
    "                                 index = [f'component_{i}' for i in range(topics)],\n",
    "                                 columns = vectorizer.get_feature_names())\n",
    "topic_word_lsa_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xword.display_topics(lsa, vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt_cv = pd.DataFrame(doc_topic_lsa_cv.round(5),\n",
    "                     index = list(docs.index),\n",
    "                     columns =  [f'component_{i}' for i in range(topics)])\n",
    "Vt_cv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_lsa_tf = lsa.fit_transform(doc_word_tf)\n",
    "sum(lsa.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_lsa_tf = pd.DataFrame(lsa.components_.round(3),\n",
    "                                 index = [f'component_{i}' for i in range(topics)],\n",
    "                                 columns = vectorizer.get_feature_names())\n",
    "topic_word_lsa_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xword.display_topics(lsa, vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt_tf = pd.DataFrame(doc_topic_lsa_tf.round(5),\n",
    "                     index = list(docs.index),\n",
    "                     columns =  [f'component_{i}' for i in range(topics)])\n",
    "Vt_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_nmf_cv = nmf_model.fit_transform(doc_word_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_nmf_cv = pd.DataFrame(nmf_model.components_.round(3),\n",
    "                                 index = [f'component_{i}' for i in range(topics)],\n",
    "                                 columns = vectorizer.get_feature_names())\n",
    "topic_word_nmf_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xword.display_topics(nmf_model, vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_cv = pd.DataFrame(doc_topic_nmf_cv.round(5),\n",
    "                    index = list(docs.index),\n",
    "                    columns =  [f'component_{i}' for i in range(topics)])\n",
    "H_cv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_nmf_tf = nmf_model.fit_transform(doc_word_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word_nmf_tf = pd.DataFrame(nmf_model.components_.round(3),\n",
    "                                 index = [f'component_{i}' for i in range(topics)],\n",
    "                                 columns = vectorizer.get_feature_names())\n",
    "topic_word_nmf_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xword.display_topics(nmf_model, vectorizer.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_tf = pd.DataFrame(doc_topic_nmf_tf.round(5),\n",
    "                    index = list(docs.index),\n",
    "                    columns =  [f'component_{i}' for i in range(topics)])\n",
    "H_tf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 1000, multi_class = 'multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = Vt_cv.merge(pc_df[['fillin_pct', 'quotes_pct', 'ques_pct', 'self_ref']], \n",
    "                           how ='inner', \n",
    "                           left_index = True, \n",
    "                           right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = Vt_cv\n",
    "X_2 = all_features\n",
    "y = pc_df.dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_1 = train_test_split(X_1, y, test_size=0.3, random_state=420)\n",
    "model_data_2 = train_test_split(X_2, y, test_size=0.3, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xword.show_cm(lr, model_data_1, colormap = 'seismic', title = \"Semantic Features Only\")\n",
    "xword.show_cm(lr, model_data_2, colormap = 'seismic', title = \"Semantic + Descriptive Features\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xword.show_cm(lr, model_data_1, colormap = 'Greys', title = \"Semantic Features Only\")\n",
    "xword.show_cm(lr, model_data_2, colormap = 'Greys', title = \"Semantic + Descriptive Features\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Letter frequency\n",
    "* Answer length\n",
    "* Named entity recognition \n",
    "* Analysis by author\n",
    "* Analysis by editor\n",
    "* Changes over time \n",
    "* Refined topic analysis\n",
    "* Consider using individual clues as docs\n",
    "* Clustering\n",
    "* Try other classifiers and ensembling (Naive Bayes?)\n",
    "* LDA?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "202.173px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
